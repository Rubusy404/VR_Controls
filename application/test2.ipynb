{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m start \u001b[38;5;241m+\u001b[39m (end \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m*\u001b[39m factor\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to grab a frame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time  # Make sure you import the time module\n",
    "\n",
    "video = cv2.VideoCapture(1)  # Changed camera index to 0\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Camera could not be accessed.\")\n",
    "    exit()\n",
    "\n",
    "handGesture = mp.solutions.hands.Hands()\n",
    "drawingTools = mp.solutions.drawing_utils\n",
    "screenWidth, screenHeight = pyautogui.size()\n",
    "total_distance = 0\n",
    "distance_count = 0\n",
    "prev_time = time.time()  # Initialize prev_time before the loop\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab a frame.\")\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "    rgbConvertedFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = handGesture.process(rgbConvertedFrame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawingTools.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            # Get coordinates for landmarks 8 and 4\n",
    "            x8, y8 = int(landmarks[8].x * frameWidth), int(landmarks[8].y * frameHeight)\n",
    "            x4, y4 = int(landmarks[4].x * frameWidth), int(landmarks[4].y * frameHeight)\n",
    "            # Calculate average position\n",
    "            avgX, avgY = (x8 + x4) // 2, (y8 + y4) // 2\n",
    "            # Draw a circle at the average position\n",
    "            cv2.circle(frame, (avgX, avgY), 15, (255, 0, 255), -1)\n",
    "            # Convert to screen coordinates\n",
    "            mousePositionX = screenWidth / frameWidth * avgX\n",
    "            mousePositionY = screenHeight / frameHeight * avgY\n",
    "            pyautogui.moveTo(mousePositionX, mousePositionY)\n",
    "\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('Virtual Mouse', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "video = cv2.VideoCapture(1)  # Adjust camera index as needed\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Camera could not be accessed.\")\n",
    "    exit()\n",
    "\n",
    "handGesture = mp.solutions.hands.Hands()\n",
    "drawingTools = mp.solutions.drawing_utils\n",
    "screenWidth, screenHeight = pyautogui.size()\n",
    "update_interval = 0.01  # Time between updates in seconds\n",
    "last_update_time = 0  # Last time the mouse was updated\n",
    "sensitivity_multiplier = 2.0  # Increase or adjust for higher sensitivity\n",
    "prev_frame_time = 0  # For calculating FPS\n",
    "movement_threshold = 5  # Minimum movement threshold in pixels\n",
    "prev_avgX, prev_avgY = 0, 0  # Previous average position\n",
    "smoothing_factor = 0.2  # Smoothing factor for cursor movement\n",
    "current_mouse_x, current_mouse_y = (0,0)  # Current mouse position\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab a frame.\")\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "    rgbConvertedFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = handGesture.process(rgbConvertedFrame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawingTools.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            x8, y8 = int(landmarks[8].x * frameWidth), int(landmarks[8].y * frameHeight)\n",
    "            x4, y4 = int(landmarks[4].x * frameWidth), int(landmarks[4].y * frameHeight)\n",
    "            avgX, avgY = (x8 + x4) // 2, (y8 + y4) // 2\n",
    "            cv2.circle(frame, (avgX, avgY), 15, (255, 0, 255), -1)\n",
    "\n",
    "            movement = np.sqrt((avgX - prev_avgX) ** 2 + (avgY - prev_avgY) ** 2) * sensitivity_multiplier\n",
    "\n",
    "            if current_time - last_update_time >= update_interval and movement > movement_threshold:\n",
    "                target_x = (screenWidth / frameWidth * avgX) * sensitivity_multiplier\n",
    "                target_y = (screenHeight / frameHeight * avgY) * sensitivity_multiplier\n",
    "                # Smoothened mouse movement\n",
    "                current_mouse_x += (target_x - current_mouse_x) * smoothing_factor\n",
    "                current_mouse_y += (target_y - current_mouse_y) * smoothing_factor\n",
    "                # Adjust mouse position to not exceed screen bounds\n",
    "                current_mouse_x = min(screenWidth, max(0, current_mouse_x))\n",
    "                current_mouse_y = min(screenHeight, max(0, current_mouse_y))\n",
    "                pyautogui.moveTo(current_mouse_x, current_mouse_y)\n",
    "                last_update_time = current_time\n",
    "                prev_avgX, prev_avgY = avgX, avgY\n",
    "\n",
    "    fps = 1 / (current_time - prev_frame_time)\n",
    "    prev_frame_time = current_time\n",
    "\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Virtual Mouse', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "video = cv2.VideoCapture(1)  # Ensure the correct camera index\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Camera could not be accessed.\")\n",
    "    exit()\n",
    "\n",
    "handGesture = mp.solutions.hands.Hands()\n",
    "drawingTools = mp.solutions.drawing_utils\n",
    "screenWidth, screenHeight = pyautogui.size()\n",
    "\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab a frame.\")\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "    rgbConvertedFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = handGesture.process(rgbConvertedFrame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawingTools.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            for id, landmark in enumerate(landmarks):\n",
    "                if id == 8:  # Index finger tip\n",
    "                    x = int(landmark.x * frameWidth)\n",
    "                    y = int(landmark.y * frameHeight)\n",
    "                    cv2.circle(frame, (x, y), 30, (0, 255, 255), -1)\n",
    "                    # Adjust the mouse position mapping to ensure balanced movement\n",
    "                    mousePositionX = np.interp(x, (0, frameWidth), (0, screenWidth))\n",
    "                    mousePositionY = np.interp(y, (0, frameHeight), (0, screenHeight))\n",
    "                    pyautogui.moveTo(mousePositionX, mousePositionY)\n",
    "\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('Virtual Mouse', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
