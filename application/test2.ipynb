{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time  # Make sure you import the time module\n",
    "\n",
    "video = cv2.VideoCapture(1)  # Changed camera index to 0\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Camera could not be accessed.\")\n",
    "    exit()\n",
    "\n",
    "handGesture = mp.solutions.hands.Hands()\n",
    "drawingTools = mp.solutions.drawing_utils\n",
    "screenWidth, screenHeight = pyautogui.size()\n",
    "total_distance = 0\n",
    "distance_count = 0\n",
    "prev_time = time.time()  # Initialize prev_time before the loop\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab a frame.\")\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "    rgbConvertedFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = handGesture.process(rgbConvertedFrame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawingTools.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            # Get coordinates for landmarks 8 and 4\n",
    "            x8, y8 = int(landmarks[8].x * frameWidth), int(landmarks[8].y * frameHeight)\n",
    "            x4, y4 = int(landmarks[4].x * frameWidth), int(landmarks[4].y * frameHeight)\n",
    "            # Calculate average position\n",
    "            avgX, avgY = (x8 + x4) // 2, (y8 + y4) // 2\n",
    "            # Draw a circle at the average position\n",
    "            cv2.circle(frame, (avgX, avgY), 15, (255, 0, 255), -1)\n",
    "            # Convert to screen coordinates\n",
    "            mousePositionX = screenWidth / frameWidth * avgX\n",
    "            mousePositionY = screenHeight / frameHeight * avgY\n",
    "            pyautogui.moveTo(mousePositionX, mousePositionY)\n",
    "\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('Virtual Mouse', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 70\u001b[0m\n\u001b[0;32m     66\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(fps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     68\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVirtual Mouse\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     73\u001b[0m video\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "video = cv2.VideoCapture(1)  # Adjust camera index as needed\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Camera could not be accessed.\")\n",
    "    exit()\n",
    "\n",
    "handGesture = mp.solutions.hands.Hands()\n",
    "drawingTools = mp.solutions.drawing_utils\n",
    "screenWidth, screenHeight = pyautogui.size()\n",
    "update_interval = 0.01  # Time between updates in seconds\n",
    "last_update_time = 0  # Last time the mouse was updated\n",
    "sensitivity_multiplier = 2.0  # Increase or adjust for higher sensitivity\n",
    "prev_frame_time = 0  # For calculating FPS\n",
    "movement_threshold = 3  # Minimum movement threshold in pixels\n",
    "prev_avgX, prev_avgY = 0, 0  # Previous average position\n",
    "smoothing_factor = 0.5  # Smoothing factor for cursor movement\n",
    "current_mouse_x, current_mouse_y = (0,0)  # Current mouse position\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab a frame.\")\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "    rgbConvertedFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = handGesture.process(rgbConvertedFrame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawingTools.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            x8, y8 = int(landmarks[8].x * frameWidth), int(landmarks[8].y * frameHeight)\n",
    "            x4, y4 = int(landmarks[4].x * frameWidth), int(landmarks[4].y * frameHeight)\n",
    "            avgX, avgY = (x8 + x4) // 2, (y8 + y4) // 2\n",
    "            cv2.circle(frame, (avgX, avgY), 15, (255, 0, 255), -1)\n",
    "\n",
    "            movement = np.sqrt((avgX - prev_avgX) ** 2 + (avgY - prev_avgY) ** 2) * sensitivity_multiplier\n",
    "\n",
    "            if current_time - last_update_time >= update_interval and movement > movement_threshold:\n",
    "                target_x = (screenWidth / frameWidth * avgX) * sensitivity_multiplier\n",
    "                target_y = (screenHeight / frameHeight * avgY) * sensitivity_multiplier\n",
    "                # Smoothened mouse movement\n",
    "                current_mouse_x += (target_x - current_mouse_x) * smoothing_factor\n",
    "                current_mouse_y += (target_y - current_mouse_y) * smoothing_factor\n",
    "                # Adjust mouse position to not exceed screen bounds\n",
    "                current_mouse_x = min(screenWidth, max(0, current_mouse_x))\n",
    "                current_mouse_y = min(screenHeight, max(0, current_mouse_y))\n",
    "                pyautogui.moveTo(current_mouse_x, current_mouse_y)\n",
    "                last_update_time = current_time\n",
    "                prev_avgX, prev_avgY = avgX, avgY\n",
    "\n",
    "    fps = 1 / (current_time - prev_frame_time)\n",
    "    prev_frame_time = current_time\n",
    "\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Virtual Mouse', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import numpy as np\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Camera could not be accessed.\")\n",
    "    exit()\n",
    "\n",
    "handGesture = mp.solutions.hands.Hands()\n",
    "drawingTools = mp.solutions.drawing_utils\n",
    "screenWidth, screenHeight = pyautogui.size()\n",
    "\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab a frame.\")\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "    rgbConvertedFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = handGesture.process(rgbConvertedFrame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawingTools.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            \n",
    "            for id, landmark in enumerate(landmarks):\n",
    "                if id == 8:  # Index finger tip\n",
    "                    x = int(landmark.x * frameWidth)\n",
    "                    y = int(landmark.y * frameHeight)\n",
    "                    cv2.circle(frame, (x, y), 30, (0, 255, 255), -1)\n",
    "                    mousePositionX = np.interp(x, (0, frameWidth), (0, screenWidth))\n",
    "                    mousePositionY = np.interp(y, (0, frameHeight), (0, screenHeight))\n",
    "                    pyautogui.moveTo(mousePositionX, mousePositionY)\n",
    "\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('Virtual Mouse', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import numpy as np\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Camera could not be accessed.\")\n",
    "    exit()\n",
    "\n",
    "handGesture = mp.solutions.hands.Hands()\n",
    "drawingTools = mp.solutions.drawing_utils\n",
    "screenWidth, screenHeight = pyautogui.size()\n",
    "\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab a frame.\")\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "    rgbConvertedFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = handGesture.process(rgbConvertedFrame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawingTools.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            x8, y8 = int(landmarks[8].x * frameWidth), int(landmarks[8].y * frameHeight)\n",
    "            x4, y4 = int(landmarks[4].x * frameWidth), int(landmarks[4].y * frameHeight)\n",
    "            x, y = (x8 + x4) // 2, (y8 + y4) // 2\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), -1)\n",
    "            mousePositionX = np.interp(x, (0, frameWidth), (0, screenWidth))\n",
    "            mousePositionY = np.interp(y, (0, frameHeight), (0, screenHeight))\n",
    "            pyautogui.moveTo(mousePositionX, mousePositionY)\n",
    "\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('Virtual Mouse', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
